#' OCR page synchronously
#'
#' Sends a single-page document to Google Document AI for synchronous (immediate) processing. Returns a response object containing the text and additional data.
#' @param file Path to a single-page pdf or image file
#' @param proj_id Your Google Cloud Services project id.
#' @param loc A two-letter region code ("eu" or "us"). Defaults to "eu".
#' @param token An authentication token generated by `dai_auth()` or another auth function.
#'
#' @return a json response object
#'
#' @details Requires a Google Cloud access token (\code{google_token}) and a certain amount of configuration in RStudio; see vignettes for details. Input files can be in either .pdf, .bmp, .gif, .jpeg, .jpg, .png, or .tiff format. Extract the text from the response object with dai::text_from_dai_response(). Inspect the entire response object with httr::content().
#' @export
#'
#' @examples
#' \dontrun{
#' response <- dai_sync("doc_page.pdf")
#'
#' my_page_scan <- "001.png"
#' response <- dai_sync(my_page_scan)
#' }
dai_sync <- function(file,
                     proj_id = get_project_id(),
                     loc = "eu",
                     token = dai_token()
                     ) {

  # Check
  if (!(is.character(file) && length(file) == 1)) {
    stop("Invalid file input.")
    }

  extension <- tolower(stringr::str_extract(file, "(?<=\\.)\\w{3,4}$"))
  supported <- c("bmp", "gif", "jpeg", "jpg", "pdf", "png", "tiff")

  if (!(extension %in% supported)) {
    stop("Unsupported file format. See documentation for details.")
    }

  if (extension == "pdf" && !(is_pdf(file))) {
    stop("Input file not a real pdf. Is the file in your working directory?")
  }

  if (!(is.character(proj_id) && length(proj_id) == 1)) {
    stop("Invalid proj_id.")
  }

  loc <- tolower(loc)

  if (!(loc %in% c("eu", "us"))) {
    stop("Invalid location parameter.")
  }

  # Encode
  if (extension == "pdf"){
    encoded_file <- pdf_to_binbase(file)
    } else {
    encoded_file <- img_to_binbase(file)
    }

  ## Create json request body
  req <- list("inputConfig" = list("mimeType" = "image/tiff",
                                   "contents" = encoded_file
                                   )
              )

  bod <- jsonlite::toJSON(req, auto_unbox = TRUE)

  ## Build URL and submit API request

  base_url <- glue::glue("https://{loc}-documentai.googleapis.com")

  path <- glue::glue("v1beta2/projects/{proj_id}/locations/{loc}")

  method <- "documents:process"

  url <- glue::glue("{base_url}/{path}/{method}")

  response <- httr::POST(url,
                         httr::config(token = token),
                         body = bod
                         )
  time <- response[[7]]
  status <- response[[2]]

  if (status == 200){
    message(glue::glue("File submitted at {time}. HTTP status: 200 - OK."))
  } else {
    message(glue::glue("File submitted at {time}. HTTP status: {status} - unsuccessful."))
  }

  return(response)
}

#' OCR documents asynchronously
#'
#' This function sends files from your Google Storage bucket to Google Document AI for asynchronous (offline) processing. The output is delivered to your bucket as json files.
#'
#' @param files A vector or list of pdf filepaths in a Google Cloud Storage bucket. Filepaths must include all parent bucket folder(s) except the bucket name.
#' @param filetype Either "pdf", "gif", or "tiff". If \code{files} is a vector, all elements must be of the same type.
#' @param dest_folder The name of the bucket subfolder where you want the json output.
#' @param bucket The name of your bucket. Not necessary if you have set a default bucket with googleCloudStorageR::gcs_global_bucket().
#' @param proj_id Your Google Cloud Services project id.
#' @param loc A two-letter region code ("eu" or "us"). Defaults to "eu".
#' @param token An authentication token generated by `dai_auth()` or another auth function.
#' @param pps An integer from 1 to 100 for the desired number of pages per shard in the JSON output. Defaults to 100.
#' @return A list of HTTP responses.
#' @details Requires a Google Cloud access token (\code{google_token}) and a certain amount of configuration in RStudio; see vignettes for details. For long pdf documents, the json output is divided into separate files (shards) of 20 pages each. Maximum pdf document length is 2000 pages. The maximum number of pages in active processing is 10,000. The function waits 10 seconds between each document submission, so I recommend using RStudio's "Jobs" functionality if you are processing a lot of files.
#'
#' NOTE: The function in its current form is a placeholder for a future function that allows for real batch processing (as opposed to an iterated single submission).
#'
#' @export
#' @examples
#' \dontrun{
#' # with daiR configured on your system, several parameters are automatically provided,
#' # and you can pass simple calls, such as:
#' dai_async("my_document.pdf")
#'
#' # NB: Include all parent bucket folders (but not the bucket name) in the filepath:
#' dai_async("for_processing/pdfs/my_document.pdf")
#'
#' # Bulk process by passing a vector of filepaths in the files argument:
#' dai_async(my_files)
#'
#' # Specify a bucket subfolder for the json output:
#' dai_async(my_files, dest_folder = "processed")
#' }

dai_async <- function(files,
                      filetype = "pdf",
                      dest_folder = NULL,
                      bucket = Sys.getenv("GCS_DEFAULT_BUCKET"),
                      proj_id = get_project_id(),
                      loc = "eu",
                      token = dai_token(),
                      pps = 100
                      ) {

  # Check and modify

  if (!(is.character(files) && length(files) >= 1)) {
    stop("Invalid files parameter.")
  }

  extensions <- tolower(stringr::str_extract_all(files, "(?<=\\.)\\w{3,4}$"))
  supported <- c("pdf", "gif", "tiff")

  if (!(all(unique(extensions) %in% supported))) {
    stop("Input file type not supported.")
  }

  if (length(unique(extensions)) > 1) {
    stop("Elements in files vector not all of the same type.")
  }

  filetype <- tolower(filetype)

  if (!(filetype %in% supported && length(filetype) == 1)) {
    stop("Invalid filetype parameter.")
  }

  if (!(filetype == unique(extensions))) {
    stop("Mismatch between filetype parameter and actual format of files.")
  }

  if (filetype == "pdf") {
    mime <- "application/pdf"
  } else if (filetype == "gif") {
    mime <- "image/gif"
  } else {
    mime <- "image/tiff"
  }

  if (length(dest_folder) > 1) {
    stop("Invalid dest_folder parameter.")
  }

  if (length(dest_folder) == 1 && !(is.character(dest_folder))) {
    stop("Invalid dest_folder parameter.")
  }

  if (length(dest_folder) == 1 && grepl("/$", dest_folder)) {
    dest_folder <- stringr::str_replace(dest_folder, "/$", "")
  }

  if (!(is.character(bucket) && length(bucket) == 1)) {
    stop("Invalid bucket parameter.")
  }

  if (grepl("^gs://", bucket)) {
    bucket <- stringr::str_replace(bucket, "^gs://", "")
  }

  if ((grepl("/$", bucket))) {
    bucket <- stringr::str_replace(bucket, "/$", "")
  }

  if (!(is.character(proj_id) && length(proj_id) == 1)) {
    stop("Invalid proj_id parameter.")
  }

  loc <- tolower(loc)

  if (!(loc %in% c("eu", "us") && length(loc) == 1)) {
    stop("Invalid loc parameter.")
  }

  if (!(is.numeric(pps) && round(pps) == pps && length(pps) == 1)) {
    stop("Invalid pps parameter.")
  }

  if (pps < 1 || pps > 100) {
    stop("Invalid pps parameter.")
  }

  # setup to return response list if several files
  response <- list()

  counter <- 1

  for (file in files){

    # build uris
    file_uri <- glue::glue("gs://{bucket}/{file}")

    if (is.null(dest_folder)) {
      dest_uri <- glue::glue("gs://{bucket}/{file}")
      } else {
      dest_uri <- glue::glue("gs://{bucket}/{dest_folder}/{file}")
      }

    ## create json request body
    req <- list("requests" = list("inputConfig" = list("mimeType" = mime,
                                                       "gcsSource" = list("uri" = file_uri)
                                                       ),
                                  "outputConfig" = list("pagesPerShard" = pps,
                                                        "gcsDestination" = list("uri" = dest_uri)
                                                        )
                                  )
                )

    bod <- jsonlite::toJSON(req, auto_unbox = TRUE)

    ## build URL and submit API request

    base_url <- glue::glue("https://{loc}-documentai.googleapis.com")

    path <- glue::glue("v1beta2/projects/{proj_id}/locations/{loc}")

    method <- "documents:batchProcess"

    url <- glue::glue("{base_url}/{path}/{method}")

    resp <- httr::POST(url,
                       httr::config(token = token),
                       body = bod
                       )

    status <- resp[[2]]

    time <- resp[[7]]

    if (status == 200){
      message(glue::glue("File {counter} of {length(files)} submitted at {time}. HTTP status: 200 - OK."))
    } else {
      message(glue::glue("File {counter} of {length(files)} submitted at {time}. HTTP status: {status} - unsuccessful."))
    }

    resp <- list(resp)

    response <- append(response, resp)

    counter <- counter + 1

    Sys.sleep(10)

  }
  return(response)
}
